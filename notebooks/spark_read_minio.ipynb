{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bf4611e601c174f023ee6d5ec1b694fc68b25a2a6a2cefb5ab3330490a5e6955"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "master = \"spark://zy-ubuntu:7077\"  \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--master {master} --driver-memory 4g --total-executor-cores 8 --executor-memory 8g --packages org.postgresql:postgresql:42.1.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"read minio\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"admin\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"password\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://127.0.0.1:9000\")  # must not use 'localhost'\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"-Dcom.amazonaws.services.s3.enableV4\", \"true\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.multipart.size\", \"104857600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------------+--------+\n|   tconst|averageRating|numVotes|\n+---------+-------------+--------+\n|tt0000001|          5.7|    1707|\n|tt0000002|          6.1|     210|\n|tt0000003|          6.5|    1466|\n|tt0000004|          6.2|     123|\n|tt0000005|          6.2|    2267|\n|tt0000006|          5.1|     127|\n|tt0000007|          5.5|     691|\n|tt0000008|          5.4|    1878|\n|tt0000009|          5.9|     155|\n|tt0000010|          6.9|    6346|\n|tt0000011|          5.2|     282|\n|tt0000012|          7.4|   10906|\n|tt0000013|          5.8|    1635|\n|tt0000014|          7.1|    4861|\n|tt0000015|          6.2|     884|\n|tt0000016|          5.9|    1262|\n|tt0000017|          4.6|     257|\n|tt0000018|          5.4|     508|\n|tt0000019|          5.3|      19|\n|tt0000020|          4.9|     282|\n+---------+-------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"s3a://imdb/2021-06/06/title.ratings.tsv\", sep=r'\\t', header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}